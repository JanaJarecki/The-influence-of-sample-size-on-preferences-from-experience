---
title: ""
author: "Jana B. Jarecki"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    keep_tex: yes
documentclass: "apa6"
classoption:
  a4paper,
  man,
  floatsintext
header-includes:
  \usepackage{natbib}
  \usepackage{threeparttable}
  \usepackage{booktabs}
  \shorttitle{test}
  \usepackage{setspace}
  \AtBeginEnvironment{tabular}{\singlespacing}
  \usepackage{times}
  \usepackage{changes}
  \definechangesauthor[name={JJ}, color=orange]{jj}
  \usepackage{upgreek}
  \AtBeginDocument{\let\maketitle\relax}
---

```{r setupknitr, include=0, cache=0}
# Run the setup in a separate chunk at the very beginning
 # Do not cache this chunk where you load libraries and set options
 # because the code has side effects
  source("setup_knitr.R")
```

```{r setupR, include=0, cache=0}
  source("./code/setup_fig.R")
  library(papaja); library(cogscimodels); library(data.table); library(BayesFactor); library(brms)
  options(papaja.na_string = "--")
  source("./code/4-evaluations-by-prior.R", chdir = TRUE)
```
\subsubsection{Qualitative predictions of the cognitive models}
\added[id=jj]{The next analyses focus on qualitative predictions from the cognitive strategies. For these analyses we pooled the observed data from both studies ($N=`r length(unique(d$id))`$) and used the participants' best-fitting models from the cognitive modeling.}

\textit{Effects on evaluations.}
In our task, the relative frequency model predicts that sample size will not affect evaluations (the relative frequencies were identical across sample sizes). In contrast, the Bayesian value updating model predicts that given different prior beliefs the frequency of experienced outcomes will change peoples' beliefs in different directions, and that this change is stronger with larger sample size. According to the Bayesian value updating model, participants with a zero-outcome prior who sample p-bets should increase their evaluations with higher sample size, but participants with a gain prior who sample \$-bets should decrease their evaluations with higher sample size. To test these hypotheses, participants were classified as relative-frequency learners, Bayesians with gain priors $\theta_G > 1$, and Bayesians with zero-outcome priors $\theta_G \leq 1$, based on the individually best-fitting cognitive model. Figure \ref{fig:fig6}a shows that, as predicted, among the Bayesian participants, those with zero-outcome priors increased their evaluations of p-bets, those with gain priors decreased their evaluations of \$-bets, and RF-type participants remained relatively stable across sample sizes. Statistical analyses by means of a Bayesian generalized linear model\footnote{regressing the (normalized, within-person z-standardized) evaluations on the predictors sample size, gamble type, and learner class (BVU-gain-prior, BVU-loss-prior, RF) with a by-participant random intercept; categorical predictors were effects-coded to facilitate interpretation of interactions \citep[for details, see][]{SingmannForthcoming}} favored a regression with the best-fitting cognitive model class as predictor over a regression excluding the cognitive model class, $BF\textsubscript{01}=`r BF_value_prior`$.

```{r, echo=FALSE, cache=FALSE}
  knitr::read_chunk("./code/fig6.R")
```

```{r fig6, cache=FALSE, fig.cap = "Mean evaluations by gamble type and best-fitting cognitive model and prior beliefs of the BVU model. \\textit{BVU}$=$Bayesian value updating model, \\textit{RF}$=$ Relative frequency model. Error bars indicate standard errors. Sample size categories see Table \\ref{tab:Lotteries}. \\textit{n} denotes the number of participants (of 80) that fall into the best-fitting model class. Evaluations are scaled to 0-1 and z-standardized at the individual level."}
```

```{r}
  d[, samplesizecat := factor(samplesizecat, levels = c("xs","s","m","l"))]
  conf <- dcast(d[condition == "experience"], 1 ~ samplesizecat, paste_msd, "confidence", label = TRUE)
```

\textit{Effects on confidence.}
\added[id=jj]{Regarding uncertainty about beliefs, the Bayesian model predicts that more evidence decreases the uncertainty about beliefs. Thus confidence should increase with sample size for Bayesian learners. The relative frequency model makes no predictions about confidence. To test this, we classified participants into Bayesian and relative-frequency learners based on the best-fitting model. Contrary to the predictions, the Bayesian participants' confidence did not consistently increase with sample size (see Figure \ref{fig:fig6}b), and a linear model of confidence  predicted by sample size category and gambletype ($M_0$) fitted the data better than a model with the model-based classification as predictor ($BF`r BF_conf_prior`$).}