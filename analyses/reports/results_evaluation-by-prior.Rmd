---
title: ""
author: "Jana B. Jarecki"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    keep_tex: yes
documentclass: "apa6"
classoption:
  a4paper,
  man,
  floatsintext
header-includes:
  \usepackage{natbib}
  \usepackage{threeparttable}
  \usepackage{booktabs}
  \shorttitle{test}
  \usepackage{setspace}
  \AtBeginEnvironment{tabular}{\singlespacing}
  \usepackage{times}
  \usepackage{changes}
  \definechangesauthor[name={JJ}, color=orange]{jj}
  \usepackage{upgreek}
  \AtBeginDocument{\let\maketitle\relax}
---

```{r setupknitr, include=0, cache=0}
# Run the setup in a separate chunk at the very beginning
 # Do not cache this chunk where you load libraries and set options
 # because the code has side effects
  source("setup_knitr.R")
```

```{r setupR, include=0, cache=0}
  source("./code/setup_fig.R")
  library(papaja); library(cogscimodels); library(data.table); library(BayesFactor); library(brms)
  options(papaja.na_string = "--")
  source("./code/4-evaluations-by-prior.R", chdir = TRUE)
```

\textit{Predictions about gamble valuations.}
\added[id=jj]{In our task, the relative frequency model predicts that sample size will not affect evaluations (the relative frequencies were identical across sample sizes). In contrast, the Bayesian value updating model predicts that given different prior beliefs the frequency of experienced outcomes will change peoples' beliefs in different directions, and that this change is stronger with larger sample size. According to the Bayesian value updating model, participants with a zero-outcome prior who sample p-bets should increase their evaluations with higher sample size, but participants with a gain prior who sample \$-bets should decrease their evaluations with higher sample size. To test these hypotheses, participants were classified as relative-frequency learners, Bayesians with gain priors $\theta_G > 1$, and Bayesians with zero-outcome priors $\theta_G \leq 1$, based on the individually best-fitting cognitive model. Figure \ref{fig:fig6}a shows that, as predicted, among the Bayesian participants, those with zero-outcome priors increased their evaluations of p-bets, those with gain priors decreased their evaluations of \$-bets, and RF-type participants remained relatively stable across sample sizes. Statistical analyses by means of a Bayesian generalized linear model\footnote{regressing the (normalized, within-person z-standardized) evaluations on the predictors sample size, gamble type, and learner class (BVU-gain-prior, BVU-loss-prior, RF) with a by-participant random intercept; categorical predictors were effects-coded to facilitate interpretation of interactions \citep[for details, see][]{SingmannForthcoming}} favored a regression with the best-fitting cognitive model class as predictor over a regression excluding the cognitive model class, $BF\textsubscript{01} `r BF_value_prior`$.
}

```{r, echo=FALSE, cache=FALSE}
  knitr::read_chunk("./code/fig6.R")
```

```{r fig6, cache=FALSE, fig.cap = "Mean evaluations by gamble type and best-fitting cognitive model and prior beliefs of the BVU model. \\textit{BVU}$=$Bayesian value updating model, \\textit{RF}$=$ Relative frequency model. Error bars indicate standard errors. Sample size categories see Table \\ref{tab:Lotteries}. \\textit{n} denotes the number of participants (of 80) that fall into the best-fitting model class. Evaluations are scaled to 0-1 and z-standardized at the individual level."}
```

\textit{Predictions about confidence.}
\added[id=jj]{Regarding uncertainty about beliefs, the Bayesian model predicts that the uncertainty about beliefs reduces with more evidence. Thus in Bayesian lerners, confidence should increase with growing sample size. The relative frequency model makes no predictions about confidence. To test this, we classified participants into Bayesian and relative-frequency learners based on the best-fitting model. Mean confidence ratings of Bayesian-type learners, z-standardized within participants, did not increase from the extra small sample size ($`r d[samplesizecat == "xs" & winner == "bvu", paste_msd(conf_scaled, label = T)]`$), to the small sample size ($`r d[samplesizecat == "s" & winner == "bvu", paste_msd(conf_scaled, label = T)]`$), medium sample size ($`r d[samplesizecat == "m" & winner == "bvu", paste_msd(conf_scaled, label = T)]`$), and large sample size ($`r d[samplesizecat == "l" & winner == "bvu", paste_msd(conf_scaled, label = T)]`$, Figure \ref{fig:fig6}b), a linear regression model ($M_0$) without the cognitive model classification as predictor but with predictors sample size category and gambletype outperformed a regression including cognitive model category as predictor ($BF_{01}`r BF_conf_prior`$).}

\added[id=jj]{This effect was even stronger when people made valuations from experience. Regarding confidence, the observed confidence of valuations from experience from description ($M = 4.04$, $SD = 1.08$). Separately for each sample-size category, we compared $\mathrm{M}\textsubscript{0}$, which predicts confidence as a function of random participant effects, with $\mathrm{M}\textsubscript{1}$, which takes condition as an additional fixed factor into account. The analyses suggest that participants were slightly more confident about their ratings from experience than from description for small ($BF\textsubscript{10} = 2.5$), medium ($BF\textsubscript{10} = 1.3$), and large ($BF\textsubscript{10} = 4.8$) sample sizes. For the extra small sample sizes ($BF\textsubscript{10} = 0.3$), confidence judgments did not differ.
}
