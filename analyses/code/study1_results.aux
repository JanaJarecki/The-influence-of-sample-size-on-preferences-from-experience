\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Ghalanos2015}
\citation{Kass1995,Lewandowsky2011}
\@writefile{toc}{\contentsline {subsubsection}{Evaluations of gambles from different sample sizes}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Cognitive modeling of experience-based evaluations}{1}{section*.4}\protected@file@percent }
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{relative frequency}{1}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{Bayesian value updating}{1}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{The models were compared to a baseline model, which predicts a constant evaluation equal to the mean individual evaluation (sensible models are expected to outperform this baseline model).}{1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Valuations of Gambles in Study 1\relax }}{2}{table.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:means_study1}{{1}{2}{Valuations of Gambles in Study 1\relax }{table.caption.3}{}}
\citation{Edwards1967,Tauber2017}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{Therefore, the relative frequency model had two free parameter, the power utility exponent $\alpha $ ($0 \leq \alpha \leq 20$) and $\sigma $. The Bayesian value updating model had four free parameter the gain prior $\theta _G$ ($0 \leq \theta _G \leq 1$), the learning rate $\delta $ ($0 \leq \delta \leq 10$), $\alpha $ and $\sigma $ with the prior on zero outcomes constrained to $\theta _0=2-\theta _G$. The baseline model had two free parameter, the mean evaluation $\mu $ and $\sigma $. We estimated the parameters using an augmented Lagrange multiplier method \citep  [Rsolnp package, version 1.16]{Ghalanos2015}. We compared the models by their evidence strength and BIC weights from the Bayesian information criterion (BIC) \cite  [evidence in favor of a model compared to the individually best-fitting model][]{Kass1995, Lewandowsky2011}. Higher weights indicate stronger evidence for a model.}{3}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{We will first outline the quantitative model fit, followed by the qualitative model fit, and lastly analyze the effects of sample size given the cognitive strategies.}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Evidence for the models for individual participants. \textit  {RF}$=$ relative frequency model, \textit  {BVU}$=$ Bayesian value updating model, \textit  {BASE}$=$ Baseline model.\relax }}{3}{figure.caption.5}\protected@file@percent }
\newlabel{fig:study1_model_weights}{{1}{3}{Evidence for the models for individual participants. \textit {RF}$=$ relative frequency model, \textit {BVU}$=$ Bayesian value updating model, \textit {BASE}$=$ Baseline model.\relax }{figure.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameter Estimates of Winning Models, \textit  {M (SD)}\relax }}{4}{table.caption.7}\protected@file@percent }
\newlabel{tab:study1_parameter}{{2}{4}{Parameter Estimates of Winning Models, \textit {M (SD)}\relax }{table.caption.7}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{ The estimated parameter of the winning models, which Table \ref  {tab:study1_parameter} summarizes, reveal that the power utility exponent ($\alpha $) is almost identical for the participants using a Bayesian value updating strategy ($M_{\alpha }= 1.49$) and those using a relative frequency strategy ($M_{\alpha }=1.61$), $M = -0.08$ 95\% HDI $[-0.91$, $0.80]$, $\mathrm  {BF}_{\textrm  {01}} = 2.76$. Participants using the Bayesian strategy had, on average, a prior belief that gains occur with 46\% (gain prior $\theta _G = 0.92$; zero-outcome prior $\theta _0 = 1.08$). Also, their estimated learning rate $\delta $ was anti-conservative ($M_{\delta }=1.36$; values $>$ 1 are liberal, 1 is optimal Bayesian, $<$ 1 is conservative learning). Liberal learning was not observed in previous data which found conservative learning \citep  {Edwards1967,Tauber2017}, but the liberal learning in our data can be explained by that participants repeatedly sampled from the same set of gambles. }{4}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{The qualitative fit between the models and the data is shown in Figure \ref  {fig:ind_fits1}, which plots the predictions of the best-fitting models against the observed evaluations. It shows that the models generally describe the data well (mean $r\textsubscript  {pred,obs} = 0.71$), except in four cases, where even the winning model fails to resemble the data qualitatively (participants number 05, 19, 24, 38, with $r\textsubscript  {pred,obs} < 0.40$). For these cases, for whom the winning model is the Bayesian updating model, the model must be rejected because of qualitative mis-fit.\rmarkdownfootnote {As robustness check we repeated the model comparison with subjective probability weighting, using Prelec\IeC {\textquoteright }s single parameter weighting function. This weighting function incorporates non-linearities in the perception of probabilities. However, the quantitative results of the probability weighting model and the utility model, we favored a utility model without probability weighting.}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Predicted evaluations from the best-fitting models plotted against the observed evaluations (by participant). \textit  {BVU}$=$ Bayesian value updating model, \textit  {RF}$=$ relative frequency model, \textit  {BASE}$=$baseline model.\relax }}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:ind_fits1}{{2}{5}{Predicted evaluations from the best-fitting models plotted against the observed evaluations (by participant). \textit {BVU}$=$ Bayesian value updating model, \textit {RF}$=$ relative frequency model, \textit {BASE}$=$baseline model.\relax }{figure.caption.8}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{The cognitive modeling results thus show that most participants used a Bayesian strategy, and some used a relative-frequency strategy. This strategy heterogeneity helps understanding the behavioral null finding---that sample size seemed to have no effect on valuations---that were observed at the aggregate level (Table \ref  {tab:means_study1}). The aggregate analysis fails to take the individual differences in learning strategies into account, while participants are best described by a mixture of strategies. Moreover, the aggregate analysis also fails to account for differences in the prior beliefs about gain probabilities. Depending on the prior belief, the Bayesian value updating (BVU) model predicts either a decrease or an increase in valuations with increasing sample size. The next analysis will focus on these differences.}{5}}
\citation{SingmannForthcoming}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{ The Bayesian model predicts that sample size changes the evaluations differently as a function of prior beliefs. Participants with a gain prior---initially believing that gains are more likely than zero-outcomes---should decrease the evaluations of \$-bets as sample sizes increase, because participants overwrite their priors through sampling and learn that gains of \$-bets are less likely than zero-outcomes. By contrast, participants with a zero-outcome prior---initially believing that zero-outcomes are more likely than gains---should increase their evaluations of p-bets as sample size increases, because they learn that gains of p-bets are more likely than zero-outcomes (see the probabilities in Table\nobreakspace  {}\ref  {table:Lotteries}). }{6}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{that includes the expected value as random effect}{6}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{that includes p-bets and \$-bets as fixed effects}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Mean evaluation (standardized to 0 - 1) by winning model and prior beliefs of the BVU model. \textit  {BVU}$=$Bayesian value updating model, \textit  {RF}$=$ Relative frequency model. Error bars indicate standard errors. \textit  {\$-bet}: low-probability high-outcome gambles, \textit  {p-bet}: high-probability low-outcome gambles. Sample sizes (xs, x, m, l), see Table \ref  {tab:Lotteries}. \textit  {n=16, 13, 6} denotes the number of participants best-described by the respective models.\relax }}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:qual1}{{3}{7}{Mean evaluation (standardized to 0 - 1) by winning model and prior beliefs of the BVU model. \textit {BVU}$=$Bayesian value updating model, \textit {RF}$=$ Relative frequency model. Error bars indicate standard errors. \textit {\$-bet}: low-probability high-outcome gambles, \textit {p-bet}: high-probability low-outcome gambles. Sample sizes (xs, x, m, l), see Table \ref {tab:Lotteries}. \textit {n=16, 13, 6} denotes the number of participants best-described by the respective models.\relax }{figure.caption.9}{}}
\@writefile{loc}{\ChangesListline {added}{Added\nobreakspace  {}(jj)}{According to Bayesian value updating higher sample sizes should increase confidence. The relative frequency model predicts no influence of sample size on confidence. We analyzed the confidence ratings by best-fitting model (Bayesian-type learners and relative-frequency-type learners). The confidence of Bayesian learners did not change remarkably across sample sizes ($M=$ for sample sizes , respectively; $SD$s$=$ , respectively). A linear model\rmarkdownfootnote {with by-participant random intercept and the predictors effect-coded.} of the confidence ratings, which excluded sample size as predictor, was preferred over a model including sample size ($BF\textsubscript  {excl,incl} = 3.01$). Similarly, the confidence of relative-frequency-type learners did not show an effect of sample size on confidence ratings ($M = $ for sample sizes , respectively; \textit  {SD}s$=$ , respectively; BF\textsubscript  {excl,incl}$= 0$)}{8}}
