\documentclass[a4paper, man, natbib, floatsintext]{apa6}
\usepackage{standalone}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\graphicspath{{analyses/code/}{analyses/figures/}}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{url}
\usepackage{rotating}
\usepackage[toc,page]{appendix}
\usepackage{color}
\usepackage{subscript}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage{longtable}
\usepackage{times}
\usepackage{upgreek}
\usepackage{setspace}
%\AtBeginEnvironment{tabular}{\onehalfspacing}
%% Revision:
%% Use "final" option to remove all tracking markups
\usepackage[authormarkup=none]{changes}
\definechangesauthor[name={JJ}, color=orange]{jj}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{The influence of sample size on preferences from experience}
\shorttitle{sample size and preference}
\author{Janine Christin Hoffart\\Jana B. Jarecki\\J\"org Rieskamp\\Gilles Dutilh}
\affiliation{University of Basel, Department of Psychology, Center for Economic Psychology}
\leftheader{Hoffart, Jarecki, Rieskamp, Dutilh}

\abstract{People often learn from experience about the distribution of outcomes and values of risky options. People typically draw small samples, when they can actively sample information about outcomes and outcome probabilities to make decisions. \added[id=jj]{We examine how the number of samples that people see in decision from experience affects preferences for risky gambles. In two studies (N=40 each) we manipulated the amount of samples that people drew from risky gambles and measured the selling prices and confidence in the selling-prices after sampling.} The results show that, on average, sample size influenced neither the selling prices nor confidence. However, \added[id=jj]{cognitive modeling of individual-level learning showed that most} participants could be classified as Bayesian learners, and the minority adhered to a frequentist learning strategy. The observed selling prices of Bayesian learners changed with sample size as predicted by Bayesian principles, whereas sample size left the judgments of frequentist learners unaffected. These results illustrate the variability in how people learn from sampled information and provide an explanation for why sample size often does not affect judgments.
}

\keywords{D--E gap, valuations from experience, \added[id=jj]{risky gambles}}
\authornote{This research is supported by a grant (SNSF \# 143854) from the Swiss National Science Foundation to the second and third author. We thank Anita Todd for editing the manuscript. 

Correspondence concerning this article should be addressed to Janine Christin Hoffart, University of Basel, Department of Psychology, Missionsstrasse 62a, 4055 Basel, Switzerland.  E-mail: janine.hoffart@unibas.ch}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

In everyday life, people often form preferences on the basis of past experiences. The strength of these preferences arguably depends on the amount of previous experience. Someone who has visited a restaurant for many years and has always had positive experiences likely has a stronger positive preference for this restaurant than someone who visited the restaurant only once and had a positive experience. Thus, even if the relative frequency of positive experiences is similar, the strength of preferences can differ depending on the amount of experience. We examined how people's preferences in an experience-based judgment situation under risk evolve as a function of growing experience. 

%In everyday life people often base their preferences on past experiences. How much experience people have made with an option arguably influences how strong people's opinion about this option is. Someone who had made 50 out of 50 good experiences with a restaurant probably has a stronger preference for this restaurant than someone who had made 1 out of 1 good experience with this restaurant although the relative frequency of good experiences is the same in both situations. Here, we study, how people's preferences (i.e. valuations) in an experience-based task evolve as a function of growing experience. 

\section{Search Effort in Experience-Based Tasks and the Description-Experience Gap (D--E gap) and }
\added[id=jj]{Search effort refers to the amount of samples that people draw in experience-based risky choice tasks. In experience-based tasks \citep[e.g.,][]{Hertwig2004, Hau2008}, people learn about the distribution of outcomes of gambles by repeatedly drawing samples from a gamble until they feel confident to make a judgment or decision. By contrast, in description-based tasks, people judge risky gambles from numerical, graphical, or textual summaries of the gambles' outcome distributions. Past research found that risk preferences differ between experience- and description-based tasks (the decision-experience gap or D--E gap). In decisions from description, people choose as if they overweight rare events \citep{Kahneman1979}, in decisions from experience, they choose as if they underweight rare events \citep{Hertwig2004}.}

The size of the sample that people draw (search effort) in experience-based tasks plays a key role in explaining the D--E gap, because smaller samples cause higher sampling error. Sampling error means that the observed relative frequency in the outcome sequence deviates from the objective outcome probability \citep{Hadar2009}. Drawing more samples diminishes the sampling error, but usually the number of samples drawn by people are not sufficient to allow inferences about the true distribution of a skewed gamble. Participants in \cite{Hertwig2004}, for instance, drew a median of 15 samples per decision, and with this number of samples, the skew of a two-outcome gamble's binomial sampling distribution implies that more people undersample than oversample  low-probability outcomes (rare events). Indeed, averaged across trials, in Hertwig et al.'s study, the rare event was undersampled by $78\%$ of the participants. Other studies have reported similar sampling errors \citep[e.g.,][]{Hau2008,Rakow2008}. Explanations for why people often search insufficiently include limits of memory, opportunity costs \citep{Hau2008}, or adaptive choice simplification \citep{Hertwig2010}: Simulations have shown that small samples amplify the differences between the observed means of the outcome distributions of risky options.

\added[id=jj]{Previous work tried to eliminate sampling error in experienced-based risky choice in order to understand the D--E gap.} Attempts have involved encouraging participants to draw larger samples \citep{Hau2008}, showing samples that represent the gambles' true probability distributions \citep{Ungemach2009}, showing large numbers of random samples \citep{Hau2008,Hau2010}, describing gambles to match the outcome distribution sampled by other participants  \citep{Rakow2008}, and only analyzing trials in which the drawn sample approximates the gambles' true outcome distribution \citep[e.g.,][]{Camilleri2009, Camilleri2011a}. Sometimes the D--E gap diminished \citep{Hau2008,Hau2010, Ungemach2009} or vanished \citep{Gloeckner2012, Camilleri2009,Camilleri2011a,Rakow2008}, but despite these mixed findings, the D--E gap is a robust phenomenon \citep[for a recent meta-analysis, see][]{Wulff2017}. \added[id=jj]{Most of this research focused on sampling error and sample size because sampling error is more likely in small samples.}

\added[id=jj]{In the present work we examine the role of sample size in experience-based preference formation without focusing on sampling error. To do so, we manipulated how many samples people drew from a risky prospects' outcome distributions (sample size) and measured people's preferences (i.e., selling prices). Aiming to isolate the effects of sample size on preferences, our design eliminated sampling error. We study how sample size influences preferences independently of sampling error.}


%While the question whether people process information from description differently than information from experience is definitely interesting, here . Instead we will focus on how sample size influences how risky prospects are evaluated. To do so, we manipulate how many samples people can draw from the prospects' outcome distributions and study

\section{How Does Sample Size Influence Preferences?}
The question of how sample size influences judgments has interested psychologists for decades \citep[e.g.,][]{Tversky1971, Griffin1992}. We investigated how sample size influences preferences from experience, contrasting two theories: \textit{the belief in the law of small numbers} \citep{Tversky1971} and \textit{Bayesian updating}. 

The belief in the law of small numbers, which was formulated by \cite{Tversky1971}, is the belief that it is highly probable that a small sequences of random draws represents the true outcome distribution. When asked to mentally produce a short sequence of random coin tosses, people produced sequences with a relative frequency of heads and tails of $.50$ more often than statistically expected \citep{Tversky1971}. In \cite{Griffin1992}, participants ignored sample size in their judgments of coin biases after seeing sequences of coin tosses of different length, some of which were biased. Participants mainly based their estimates of the probabilities associated with the coins on the observed relative frequency of heads and tails. Surprisingly, participants expressed higher confidence in their judgments when the number of coin tosses was small, \added[id=jj]{whereas from a statistical perspective, confidence should be lower for smaller samples.} Several studies have found that people's inferential \citep[e.g.,][]{Kutzner2016}, perceptual \citep[e.g.,][]{Kvam2016}, and preferential judgments \citep[e.g.,][]{Powell2017} are less sensitive to sample sizes than expected by normative models.

In contrast to the belief in the law of small numbers, Bayesian psychological principles suggest that not only the relative frequency of outcomes but also sample size influences judgments. The Bayesian view offers a normative solution to how people deal with sample sizes. People can treat sample size as a measure of uncertainty, knowing that small samples can lead to a biased representation of the true outcome distribution and larger samples to a more veridical description of the true outcome distribution, and there is some evidence that people treat sample size as a measure of uncertainty, for instance, when they report preferences for consumer goods \citep{DeMartino2017}, make judgments about group differences \citep{Obrecht2010}, or student performance \citep{Fiedler2002}.

\subsection{Cognitive Models and Hypothesis}
To contrast the Bayesian principles with the belief in the law of small numbers in experience-based probability learning we specified two computational learning models. Before introducing the models, it is crucial to recognize that our experimental methods employ predefined sample sizes and representative sequences. In our experiments, participants sampled a \textit{predefined} number of times from a gamble's outcome distribution and evaluated it by indication of the gamble's selling price. Gambles were two-outcome gamble characterized by a gain and a zero-outcome. Individual gambles were presented with different sample sizes and these sample sequences were \textit{representative} of the gamble's true outcome distribution, which allowed us to isolate the effect of sample size without sampling error. For our task the models were formalized as models of learning the probability of the nonzero gain outcome (extending the models for cases with different outcomes is possible).

We follow an expected utility approach \added[id=jj]{and represent preferences about risky options by subjective utility functions; the subjective value of a risky option $V$ is the sum of the subjective utilities of the outcomes weighted by the outcome probabilities. We used a power utility, $u(g) = g^{\mathrm{\alpha}}$, where $g$ is the gain outcome and $\alpha$ is a free parameter. The resulting expected utility is then converted back to the monetary scale. When outcome probabilities must be learned, which is the case in experience-based decision making, true probabilities are replaced by the decision makers' beliefs $B$ given the learning model $m$ about outcome probabilities; the predicted valuation after seeing sample number $t$ is}

$$V_{\mathrm{m}, t} = \sqrt[\mathrm{\alpha}]{{B}_{\mathrm{m}, t} \times u({g})}$$where $m \in$ RF, BVU denotes the Bayesian updating and the relative frequency model (respectively). The two models differ with regard to how people form beliefs $B$ about the outcome probabilities.

\subsubsection{Relative frequency model}

\added[id=jj]{The \textit{relative frequency model (RF)} forms beliefs about probabilities from relative frequencies. It formalizes how people, who trust in the law of small numbers, estimate probabilities.} This model predicts that after sampling $t$ times the belief about the probability of a gain corresponds to the observed relative frequencies of gains
$${B}_{\mathrm{RF}, t}  =  \frac{n_t}{t} ,$$
\added[id=jj]{where $n_t$ represents the number of gains observed until sample number $t$ (including $t$).}

\added[id=jj]{The relative frequency model suggests that changes in sample size do not change the resulting valuations unless the sample size changes the observed relative frequencies. The relative frequency model does not incorporate prior beliefs about the probabilities of the outcomes.}

\subsubsection{Bayesian value updating model}
The \emph{Bayesian value updating (BVU)} model implements a Bayesian perspective on probability learning and the resulting uncertainty from sampling. \added[id=jj]{According to Bayesian principles people form beliefs about probabilities based on the observed frequencies of gains in combination with prior beliefs about outcome probabilities. The Bayesian model formalizes the beliefs about gain probabilities by a beta distribution ${B}_{\mathrm{BVU}} \sim Beta(a,b)$ \cite[for an introduction to Bayesian cognitive models, see][]{Griffiths2008a}. Initially (at $t = 0$) beliefs are represented by a prior belief distribution $B_{\mathrm{BVU},0} \sim Beta(\theta_G$, $\theta_0)$, with person-specific parameters $\theta$. The prior belief is updated from the sampled number of gains and zero-outcomes; the updated beliefs after the $t$th sample follow the distribution}

$$B_{\mathrm{BVU},t} \sim Beta(\theta_0 + \delta n_0, \theta_G + \delta n_t), \text{with } n_0 = t-n_t,$$

\added[id=jj]{where $\delta$ is a learning rate to account for individual differences in conservatism \citep{Edwards1967,Tauber2017}; the values $n_t$ is the counts of gain outcomes after sample $t$; parameter $\theta_G$, $\theta_0$ are the shape parameter of the prior Beta distribution for gains and zero-outcomes, respectively. The point estimate for the updated belief about the gain probability equals the posterior mean of this distribution, ${B}_\mathrm{BVU, t} = \frac{C}{C + D}$, with $C = \theta_G + \delta n_t$ and $D=\theta_0 + \delta n_0$.}

The learning process of the Bayesian (BVU) model's is illustrated in Figure \ref{fig:sensi}\added[id=jj]{, showing the model's beliefs about the probability of a gain as a function of the number of samples that the model saw and the prior beliefs about the gain probability. The orange curves show different initial beliefs, the purple and black curve illustrate the change in belief after observing a small representative sample of outcomes (\textit{t}$=$5) and a large representative sample (\textit{t}$=$30, samples have equal relative frequencies). For large samples, the beliefs approximate the true probability of the gamble, independently of the prior belief. In contrast, for small samples, the prior belief changes the models' posterior belief about the gamble's gain probability (purple curve). Unlike the Bayesian model, the relative frequency model predicts a constant probability $Pr(\text{gain})$ equal to the true $Pr(\text{gain})$ after the model saw the representative sequence of outcomes, such as 1 in 5 gains or 6 in 30 gains.}

\begin{figure}[htbp] 
  \centering
\includegraphics[width=1\linewidth, keepaspectratio]{fig1.eps}
  \caption{\added[id=jj]{\textit{Model behavior of the BVU model given different gambles, sample sizes, and priors.} Model beliefs are obtained using $\delta=1$. (a) Beliefs about a gamble with low gain probability. Shown are the distribution, mean, and quantile interval of the prior belief and the posterior beliefs after seeing samples of size 5 and 30 (small and large, resp); left, middle, and right panels show model behavior for three types of prior beliefs. (b) Beliefs about a gamble with high gain probability.}}
  \label{fig:sensi}
\end{figure}

The BVU model predicts that sample size and the prior influence valuations. This is because as sample size increases, the beta-distributed belief shifts from the mean of the prior belief in the direction of the true underlying probability of the gain  (see Figure \ref{fig:sensi}). Whether the model predicts a decrease or an increase in valuations with growing sample size depends on the shape of the prior belief and the true gain probability. For true gain probabilities lower than 50\% and a uniform prior belief or a prior belief peaked over highly probable gains, the valuations should decrease as a function of sample size, according to the BVU model. If the prior is peaked over losses, however, the BVU model predicts that valuations increase as a function of sample size. For gain probabilities  larger than 50\% and uniform or loss-priors valuations should increase with sample size, and decrease for priors peaked over gains. In all cases, the probability belief gets increasingly peaked around the true probability of the gain as sample size grows. Therefore, the model also predicts that confidence in valuations increases with increasing sample size. %We also test this prediction by assessing confidence ratings.

Following \cite{Griffin1992}, we also asked participants for their confidence in their valuations. We tested whether people would be more confident about their responses when the sample size was small, as found by \cite{Griffin1992}. 

\section{Study 1}
In Study 1, we aimed to measure the preference strength for risky prospects, and therefore, we prompted participants to evaluate individual gambles \citep[similer to e.g.,][]{Ashby2014, Golan2014, Pachur2012}, because evaluations allow us to measure preference strength more precisely than binary choices between gambles. This is important, as detecting subtle differences in strength of preference requires fine-grained measurement scales. Second, we aimed to lay bare the precise effects of sample size---therefore, we presented each gamble with various sample sizes. \added[id=jj]{We presented representative samples, which eliminates sampling error and allows} for an unbiased comparison of the effects of sample sizes. However, the order of outcomes within a sampling sequence was random. \added[id=jj]{A third, but sub-ordinate, goal was comparing valuations from experience with valuations from description.} Therefore, we added a block where people made valuations from description. However, as our main goals involved studying how preferences change as a function of sample size, we refrained from manipulating the order of the experience and description blocks. All people made valuations first from experience and afterward in a separate block from description. 

In Study 1, we examined how people form valuations from experience when they know the possible outcomes before they start sampling. In a situation where the outcomes are known, learning is simplified because participants only need to learn the outcome probabilities from experience. 

\subsection{Method}
\subsubsection{Participants}
Forty people (31 women, 9 men) from the participant pool of the University of Basel between 18 and 40 years old ($M = 23.41$ years, $SD = 4.86$) participated in the study. Participants could choose between a show-up fee of 10 CHF (approximately \$11.10 at the time of the experiment) or course credit. Additionally, each participant received a bonus payment that depended on the outcome of a randomly selected trial ($M = \$6.38$, $SD = \$7.62$).

\subsubsection{Stimuli and Design}
\added[id=jj]{The design was a within-subject design, participants evaluated two-outcome gambles from experience and from description. Six gambles wtih a gain or zero outcome were created by crossing two gamble types (\textit{\$-bet}, \textit{p-bet}) with three expected values (2.00, 3.20, 4.00), see Table \ref{table:Lotteries}. Three gambles offered a high gain with low probability (\$-bet), and three offered a small gain with high probability (p-bet, notation following \citealp{Lichtenstein1971}). In the experience-based valuation each gamble was crossed with four sample sizes: extra small, small, medium, large (xs, s, m, l, respectively), which are listed in Table \ref{table:Lotteries}. The extra small size (xs) consisted of 5, 6, or 7 samples, which allowed us to represent rare events of 1/5, 1/6, and 1/7 (20\%,  17\%, 14\%, respectively). The small sample size equaled xs $\times$ 2, medium equaled xs $\times$ 3, and large equaled xs $\times$ 6. Participants saw each gamble with each sample-sizes three times in fully randomized order (each gamble was seen 12 times).} %For illustration of the different sample sizes, consider Gamble 1 in Table~\ref{table:Lotteries}. It is a \$-bet that offers a gain of 16 with a probability of 1/5 (20\%). The different sample-size categories for this gamble are xs (five observations, one gain), s (ten observations, two gains), m (15 observations, three gains), and l (30 observations, six gains).}

\added[id=jj]{To avoid memory effects between trials, 18 filler trials were shown, that involved six gambles with outcomes identical to Table~\ref{table:Lotteries}, but probabilities changed to 75\% (\$-bets) and 25\% (p-bets). The filler gambles' sample sizes were 4, 8, and 16. Filler trials were excluded from analyses, because they only aimed at minimizing memory-effects.}

\begin{table}[bth]
\begin{center}
\begin{threeparttable}
\caption{Gambles and Sample Sizes Used in Studies 1 and 2\label{table:Lotteries}}
\begin{tabular}{llccccccc}
\toprule
 &  &  &  &  & \multicolumn{4}{c}{Sample Size} \\
\cmidrule(r){6-9}
Gamble ID & Type & X & Pr & EV & xs & s & m & l\\
\midrule
1 & \$-bet & 16.00 & 0.20 & 3.20 & 5 & 10 & 15 & 30\\
2 & \$-bet & 12.00 & 0.17 & 2.00 & 6 & 12 & 18 & 36\\
3 & \$-bet & 28.00 & 0.14 & 4.00 & 7 & 14 & 21 & 42\\
4 & p-bet & 4.00 & 0.80 & 3.20 & 5 & 10 & 15 & 30\\
5 & p-bet & 2.40 & 0.83 & 2.00 & 6 & 12 & 18 & 36\\
6 & p-bet & 4.70 & 0.86 & 4.03 & 7 & 14 & 21 & 42\\
\bottomrule
\addlinespace
\end{tabular}
\begin{tablenotes}[para]
\normalsize{\textit{Note.} \textit{X} = gain in Swiss Fr., \textit{Pr} = probability of gain, \textit{EV} = expected value, \textit{Sample Size} = total number of observations in the experience condition categorized as \textit{xs} = extra small, \textit{s} = small, \textit{m} = medium, \textit{l} = large. The probability is expressed as the ratio of the relative frequency of the number of gain observations to the number of observations in the smallest sample size category (xs) of this gamble, namely 1/5, 1/6, 1/7, 4/5, 5/6, and 6/7 for gamble IDs 1 through 6, respectively.}
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}

After the experience block, participants valued each gamble three times in a descriptive format. In this block, participants received a description of the gamble's outcome and the associated probability; probabilities were rounded to one decimal place (1/5 = 20\%, 1/6 = 16.7\%, 1/7 = 14.3\%). Again, presentation order of all trials was fully randomized.


\subsubsection{Procedure}
Participants read printed instructions and completed a questionnaire that ensured their understanding of the instructions; the experimental task was computerized. \added[id=jj]{Participants judged the value of risky gambles (see Table~\ref{table:Lotteries}) and rated the confidence in their judgments. Gambles were judged one-by-one, in an experience-based format given different sample sizes, followed by a description format. In the experience format, participants were informed about the outcomes but not the probabilities of a gamble, which they learned by repeatedly sampling outcomes. The possible outcomes were represented by numbers in a circle (gains were in a black circle, zero-outcomes white) and stayed on screen throughout sampling. Pressing the space bar sampled an outcome; the realized outcome appeared as a black or white circle for 250 ms; sampling ended after a predefined sample size (listed in Table~\ref{table:Lotteries}). Participants were informed a priori about the pre-specification of the sample size. The sampled outcomes were representative for the gambles (i.e., drawing a sample of size 5 from a gamble with $Pr(\text{gain})=20\%$) yielded 1 gain and 4 zeros). After sampling, participants judged the gamble and reported confidence, and proceeded to the next trial. Sample size changed from trial to trial. } The trial order and outcome sequence within a trial was randomized for individual participants. \deleted[id=jj]{After participants had drawn the required number of outcomes, they were prompted for (1) their valuation of the gamble (see below) and (2) their confidence in their valuation} 

Confidence was measured on a 7-point Likert scale (from 0 = \textit{very unconfident} to 6 = \textit{very confident}). Valuations of gambles were measured as selling prices following the Becker--DeGroot--Marschak (BDM) method \citep{Becker1964}: \deleted[id=jj]{For each gamble}Participants stated their selling prices in terms of the lowest monetary amount for which they would give up the right to gamble. Prices could range from 0.00 to the current gain in CHF, with increments of 0.10 CHF. The BDM auction was incentivized as follows. The selling price that a participant entered was compared to a random value drawn from all possible selling prices in the trial. If this random number was larger than the stated selling price, the participant ``sold'' the gamble and received a monetary amount \replaced[id=jj]{that equaled}{equal to} the random number. If the random number was equal to or smaller than the selling price, the participant got to gamble. For the BDM, the optimal strategy is always to report the true selling price.\footnote{\label{logic.BDM} 
To understand this logic, consider the following example: A person has a true selling price for a given gamble of \$3. If this person sets her selling price too low (e.g., \$2) and the randomly generated number is \$2.10, she sells her gamble for a lower price than her true selling price. If, however, she sets her selling price too high (e.g., \$5) and the randomly generated number is \$4, she keeps and plays her gamble, although she actually would have preferred to receive the \$4.
} Detailed instructions as well as an example of the BDM auction were presented to explain the auction's mechanism. We used a short questionnaire to ensure that all participants had understood how the auction worked.

\subsection{Results}
\added[id=jj]{All analyses were conducted in the statistical programming environment R version 6.0.1 \citep{R}; linear modeling was conducted with he bmrs package version 2.10 \citep{Burkner2018} using weakly or non-informative priors;
%s were compared using the BayesFactor package version 0.9.12 \citep{BayesFactor};
inferences were based on the Bayes factor ($BF\textsubscript{ij}$).}\footnote{Bayes factors quantifiy how much more or less likely the data are under Model i ($\mathrm{M}\textsubscript{i}$) than Model j ($\mathrm{M}\textsubscript{j}$). A Bayes factor of 1 ($BF\textsubscript{ij} = 1$) means that the data do not discriminate between the two models $\mathrm{M}\textsubscript{i}$ and $\mathrm{M}\textsubscript{j}$. A Bayes factor of 5 (i.e., $BF\textsubscript{ij} = 5$) means that the data are 5 times more likely under $\mathrm{M}\textsubscript{i}$ than under $\mathrm{M}\textsubscript{j}$. A Bayes factor of $1/5$ ($BF\textsubscript{ij} = 1/5$) means that the data are 5 times more likely under $\mathrm{M}\textsubscript{j}$ (note that $BF\textsubscript{ji} = 1/BF\textsubscript{ij}$).} 

\input{analyses/reports/results_study1}

\subsection{Discussion of Study 1}

Study 1 shows that the size of the sample overall did not have an effect on valuations from experience. \added[id=jj]{Cognitive modeling revealed that the majority of participants followed Bayesian principles and treat sample size as a measure of uncertainty. A minority of participants used a relative frequency strategy and disregarded sample size.} Valuations also differed when made from description versus experience. Interestingly, this difference is the opposite of the classic D--E gap that has been reported in choice paradigms: We found evidence that people behaved as if they overweighted rare events when making valuations from description \textit{and} experience. Notably, this overweighting of rare events was even stronger for the experience condition. Importantly, people assigned higher valuations to \$-bets (i.e., gambles that provide a high reward with low probability) than p-bets (i.e., gambles that provide a small reward with low probability) even when both gambles had similar expected values. This finding is in line with recent research that suggested people overweight extreme outcomes in experience-based tasks \citep{Ludvig2017}.

\section{Study 2}
In Study 1, participants knew the outcomes before drawing samples. Knowing the outcomes differs from typical decisions from experience paradigms, in which people learn about the outcome values by sampling. To bring our method more in line with this paradigm, in Study 2 we changed the experimental method such that one outcome had to be learned during sampling.

\subsection{Methods}
The procedure an methods of Study~2 were similar to Study~1. The only difference consisted in that before participants started sampling, they were now only informed about gambles being two-outcome gambles and that one of the outcomes was zero. Unlike in Study 1, the gain amounts of the gambles were not displayed on screen before or during the sampling stage.

Forty people (38 women, 2 men) between 18 and 27 years old ($M = 21.1$ years, $SD = 2.05$), recruited from the subject pool of the University of Basel, participated. We followed the incentive scheme of Study 1. On average, participants earned a bonus of 7.16 CHF ($SD = 6.91$ at the time of the study). For the data analysis, we compared the same statistical models as described in Study 1.

\subsection{Results}
All analyses were conducted in the statistical programming environment R, models were fit as in the analyses in Study 1.

\input{analyses/reports/results_study2}

\subsection{Discussion of Study 2}
Study 2 tested whether the results of Study 1  generalize to typical sampling paradigms where people have to learn the outcome values from experience. The results of Studies 1 and 2 are very similar: participants mean evaluations were not influenced by sample size systematically, and in line with Study 1, we found that a substantial proportion of people could be classified as Bayesian learners. In Study 2, however, a greater proportion of people was described by a \added[id=jj]{potentially cognitively simpler} relative-frequency-based cognitive model.

\section{Test of Qualitative Predictions from the Cognitive Models}
\added[id=jj]{
The next analyses examine qualitative predictions from the Bayesian value updating and the relative-frequency account of learning probabilities. For these analyses we pooled the observed data from both studies (N= 80), the analyses use the best-fitting models from the cognitive modeling results.
}

\input{analyses/reports/results_evaluation-by-prior}

\subsubsection{Discussion of the qualitative cognitive model predictions}
The prior beliefs in Bayesian-type  learners across both experiments interacted with the experience to produce evaluations in line with Bayesian principles. However, participants' confidence did not  increase with growing sample sizes, as would be expected from a Bayesian viewpoint. If there was any trend, it seemed that confidence decreased with growing sample size, which is in line with \cite{Griffin1992}.
%Further, we found evidence that people were more confident in their valuations from experience than their valuations from description.

\section{General Discussion}
A number of studies have shown that the amount of experience with the outcome distribution of risky prospects affects risk preferences and risky choice. We manipulated the amount of experience (sample size) with risky options in order to investigate specifically, how the sample size influences risk preferences and preference formation in the gain domain.

\added[id=jj]{Study 1 consisted of an experience-based sampling task in which participants were informed about the outcomes of two binary risky options and learned about the probabilities by sampling outcomes, designed to examine the effect of variation in sample sizes on people's evaluation of risky gambles after sampling.  To this end we manipulated the amount of samples participants drew within-subjects and rigged the relative frequencies  during sampling to be representative of the expected value, which allowed us to isolate the effects of sample size on judgments controlling for the effect of sampling error. We tested if participants follow a relative frequency (RF) strategy or Bayesian value updating (BVU). Most participants' value judgments post sampling were best described by the BVU model with an initial belief in the low outcome being more likely than the high outcome, that was quickly overcome by anti-conservative learning from experience. Only around a quarter of participants were best-described by the RF strategy. Participants' confidence in evaluations, however, were not substantially affected by sample sizes.}

\added[id=jj]{Study 2 followed a comparable logic, but in this design, the gamble's outcomes were not known to participants prior to learning but had to be learned as well. Again, the size of the samples that participants drew was manipulated. The results are in line with the first study: while mean evaluations and confidence were largely unaffected by the sample size manipulation, cognitive modeling results showed that a Bayesian strategy described the behavior of the majority of participants well (57\%) and that the learners had an initial belief that low outcomes are more likely than high outcomes but it was overcome fast by anti-conservative learning.}

\added[id=jj]{A minority of participants in both studies was described by a relative frequency strategy, which is in line with previous findings suggesting that people believe in the representativeness of short sequences of outcomes \citep{Griffin1992, Tversky1971}. This finding helps explain why people in experience-based tasks often do not sample much: If people believe that a short sequence of outcomes represents a prospect's outcome distribution comprehensively, they do not need to sample much, as they believe that sampling more will not yield new information. }

Our results suggests a substantial degree of strategy heterogeneity that goes beyond heterogeneity in the number of samples that people draw in experience-based risky choice. It is an open question why some of our participants behaved according to Bayesian principles and others did not, and future research is needed to examining what factors influence whether people behave according to Bayesian principles. One possible candidate that mediates what strategy people use is numerical literacy, which has been shown in previous work to be related to performance in Bayesian reasoning tasks \citep{Brase2017}.

\subsubsection{The role of prior beliefs}
\added[id=jj]{The BVU model assumes that people start sampling with an initial belief about the probabilities of different outcomes. Our data suggest that most Bayesian learners started with a higher prior on the lower outcome, but that the incoming experience quickly overcame the initial beliefs. In contrast to previous work, which has indicated that people are slow Bayesian updaters, we find that people update quicker than optimal Bayesian with a liberal learning rate.}

We have assumed that over the course of the experiment and across different gambles, people's prior beliefs do not change. However, recent research suggests that knowing the gain amount elicits a more informed prior belief about the probability. Under uncertainty, people's beliefs about gain probabilities are informed by the gain amount: Large gains are believed to be less likely than small gains when no other information about a gamble than the gain amount is given \citep{Pleskac2014, Hoffart2018}. If in our studies people indeed used gain amounts as predictors of the probability and integrated this information with their samples, this can explain why we see only a small effect of sample size on gamble valuations. This is because in our experimental design large gains were indeed less likely than small gains. Thus, it corresponded to the probability--reward pattern that people might presuppose. If people start sampling with prior probability beliefs that correspond closely to the real outcome probabilities, new incoming information does not shift probability beliefs as dramatically as when the prior beliefs are uninformed (e.g., uniform priors). Future research could investigate this hypothesis, for instance, by investigation how sample size influences valuations in \textit{nonrepresentative} environments, such as environments where the size of a reward/gain is uncorrelated with the probability that it occurs.

\subsection{Description versus experience in choice and valuation}
\added[id=jj]{Our findings in Study 1 differ from the classic description-experience gap, that is our participants did not behave as if they overweight rare events from description and underweight rare events from experience. In our valuation tasks participants behaved as if they overweighted rare events from both description and experience, when they were informed about the outcomes before sampling.}

Importantly, in contrast to standard experience-based choice tasks where participants experience two lotteries and make binary choices, our participants had to evaluate one individual gamble in each trial. \cite{Lichtenstein1971}, for instance, report preference reversals when people evaluate rather than chose options (a person who chooses Gamble A over Gamble B may assign a higher value to Gamble B than to Gamble A). Our valuation data is not in line with other work on evaluations from experience, that finds stronger over-weighting of rare events in an experience- than a description-format \citep{Golan2014}, but this design differs from our task in that it did not use representative outcome sequences. As we argued in the Introduction, in free-sampling paradigms, the experienced relative frequencies of outcomes do not necessarily match the underlying probability and the resulting sampling error might have contributed to the difference in the results. It is further conceivable that people show different information processing in free- and forced-sampling paradigms. For instance, people may pay more attention to a voluntarily sampled outcome than to a sampled outcome that resulted from a forced sampling decision.

\subsubsection{Buying versus selling prices}
In our experiments, we assessed preferences by asking people for selling prices for gambles. 
The endowment effect describes that people attach higher value to goods when they sell them than when they buy them \citep{Thaler1980}. \cite{Pachur2012} demonstrated this endowment effect in an experience-based task. It would be interesting to replicate our experiments with buying instead of selling prices and more rigorously compare the results with buying and selling prices from description. However, this was beyond the scope of the present study. Here, our main focus was to investigate whether preferences are influenced by sample sizes. This question can be answered independently of response format. Irrespective of whether people are asked for selling prices or buying prices or make repeated choices, the Bayesian model predicts an effect of sample size on valuations. 

\subsubsection{Confidence in valuations from description and experience}
People were more confident with their gamble valuations from experience than from description. This finding is remarkable given that from a normative perspective one could argue that people feel more confident when making valuations from description than when making valuations from experience. This is because valuations from description do not entail any uncertainty about the outcome distributions, whereas valuations from experience may entail such uncertainty.

Our findings do support research by \cite{Bradbury2014}. They reported that people who made investment decisions in the laboratory felt better informed and were more confident about their decisions from experience than those from description.
Potentially, people perceive and process experienced information differently from described information \citep{Kahneman2009}: 
While information that is described is more abstract, experienced information has direct salience or impact. When people draw a sample, they not only observe the outcome but also experience emotional reactions resulting from that observation. Thus, people do not only learn plain facts about the outcome distribution; they also gain a more vivid understanding of this distribution. This more concrete understanding of the gamble can help people access their preferences and thus creates higher confidence in valuations.




\bibliography{refJanine,references}

%\section{Footnotes}



%Kahnemann (2009): In fact, people are poor forecasters of their future emotions and future tastes—they need help in this task—and I believe that one of the responsibilities offinancial advisors should be to pro-vide that help.

\end{document}


% Please see the package documentation for more information
% on the APA6 document class:
%
% http://www.ctan.org/pkg/apa6
%